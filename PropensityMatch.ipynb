{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "import networkx as nx\n",
    "\n",
    "pd.options.display.max_seq_items = 2000\n",
    "\n",
    "# Two crs, one for coordinates and a projected one to compute areas\n",
    "crs_geographical = \"epsg:4326\"\n",
    "crs_projected = \"epsg:28992\"\n",
    "\n",
    "# Confounder names\n",
    "confounders = [ \n",
    "           \"P_00_14_JR\", 'P_15_24_JR','P_25_44_JR','P_45_64_JR', 'P_65_EO_JR',  # Age distribution\n",
    "           'P_LAAGINKP', 'BEV_DICHTH', 'WWB_UITTOT', 'WW_UIT_TOT', 'AO_UIT_TOT' # Confounders\n",
    "           ]\n",
    "\n",
    "# Small number to add \n",
    "epsilon = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.528108629721533 1.0\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "gdf = gpd.read_file(\"data/prepared_data.csv\", \n",
    "                    GEOM_POSSIBLE_NAMES=\"geometry\", # Having a column named 'geometry' is too hard for geopandas\n",
    "                    KEEP_GEOM_COLUMNS=\"NO\")\n",
    "\n",
    "# Don't ask me where this column came from\n",
    "gdf.drop([\"field_1\"], axis=1, inplace=True)\n",
    "\n",
    "# Set the columns as floats \n",
    "for col in confounders + [\"percent_green\", \"percent_blue\", \"DEPRESSION_RISK\"]:\n",
    "    gdf[col] = gdf[col].astype('float')\n",
    "\n",
    "    # Normalize the column \n",
    "    gdf[col] = (gdf[col] - gdf[col].min()) / (gdf[col].max() - gdf[col].min())\n",
    "    # print(gdf[col].min(), gdf[col].mean(), gdf[col].max() )\n",
    "\n",
    "print(gdf[\"DEPRESSION_RISK\"].min(), gdf[\"DEPRESSION_RISK\"].mean(), gdf[\"DEPRESSION_RISK\"].max() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropensityMatching():\n",
    "    def __init__(self,\n",
    "                 name,\n",
    "                 y,\n",
    "                 z, \n",
    "                 conf,\n",
    "                 null = False\n",
    "        ) -> None:\n",
    "\n",
    "        self.name = name\n",
    "        self.y = y.values\n",
    "        self.z = z.values\n",
    "        if null:\n",
    "            np.random.shuffle(self.z)\n",
    "        self.conf = conf\n",
    "        \n",
    "\n",
    "    # TODO: Maybe make more bins that are uneven\n",
    "    # TODO: More bins when we get more data? \n",
    "    def CalculatePropensityScore(self, nbins, plot=False):\n",
    "        edges = np.array([-0.000001] + list(np.linspace(0.00000001, self.z.max()+epsilon, nbins)))\n",
    "\n",
    "        self.discrete= pd.cut(self.z, bins=edges, labels=np.arange(0,nbins))\n",
    "        \n",
    "        if plot:\n",
    "            # TODO: Make this look nice\n",
    "            plt.hist(self.discrete, bins=nbins)\n",
    "            plt.show()\n",
    "        \n",
    "        mod_log = OrderedModel(self.z, self.conf, distr='logit')\n",
    "\n",
    "        res_log = mod_log.fit(method='bfgs', disp=False)\n",
    "\n",
    "        predicted = res_log.model.predict(res_log.params, exog=self.conf)\n",
    "        print(type(predicted))\n",
    "\n",
    "        self.propensity = np.array([predicted[i, self.discrete[i]] for i in range(len(self.z))])\n",
    "        return self.propensity\n",
    "\n",
    "\n",
    "    def DistanceMatrix(self):\n",
    "        self.d = np.zeros(shape=(len(self.z), len(self.z)))\n",
    "\n",
    "        for i in range(self.d.shape[0]):\n",
    "            for j in range(self.d.shape[1]):\n",
    "                self.d[i,j] = (abs(self.propensity[i] - self.propensity[j])) / (abs(self.z[i] - self.z[j])+epsilon)\n",
    "        return self.d\n",
    "\n",
    "\n",
    "    def MinWeightMaximalMatch(self):\n",
    "        G = nx.Graph(self.d)\n",
    "        match_unordered = nx.min_weight_matching(G)\n",
    "\n",
    "        # array with low in col 0 and high in col 1\n",
    "        self.match = np.zeros(shape=(len(match_unordered), 2), dtype=int)\n",
    "\n",
    "        for idx, pair in enumerate(match_unordered):\n",
    "            i = pair[0]\n",
    "            j = pair[1]\n",
    "            if self.z[i] < self.z[j]:\n",
    "                self.match[idx,0] = i\n",
    "                self.match[idx,1] = j\n",
    "            else:\n",
    "                self.match[idx,0] = j\n",
    "                self.match[idx,1] = i\n",
    "        return self.match\n",
    "\n",
    "\n",
    "    def TreatmentEffect(self, threshold=None):\n",
    "        self.TE = []\n",
    "        for i, j in self.match:\n",
    "            te = (self.y[i] - self.y[j])/(self.z[i] - self.z[j])\n",
    "            if not threshold or abs(te) < threshold:\n",
    "                self.TE.append(te)\n",
    "        self.TE = np.array(self.TE)\n",
    "        self.ATE = np.sum(self.TE)\n",
    "        return self.TE, self.ATE\n",
    "    \n",
    "    \n",
    "    def HighAndLowGroups(self, dec=4):\n",
    "        high = []\n",
    "        low = []\n",
    "        for i, j in self.match:\n",
    "            low.append(self.z[i])\n",
    "            high.append(self.z[j])\n",
    "\n",
    "        print(f\"Treatment distribution over high and low groups\")\n",
    "        print(f\"High: mean={round(np.mean(high),dec)}, std={round(np.std(high),dec)}, min={round(np.min(high),dec)}, max={round(np.max(high),dec)}\")\n",
    "        print(f\"Low: mean={round(np.mean(low),dec)}, std={round(np.std(low),dec)}, min={round(np.min(low),dec)}, max={round(np.max(low),dec)}\")\n",
    "    \n",
    "    def DescribeTreatmentEffect(self, dec=3):\n",
    "        print(\n",
    "            self.name, \n",
    "            round(self.ATE, dec),\n",
    "            round(self.TE.min(), dec),\n",
    "            round(np.percentile(self.TE, 25), dec),\n",
    "            round(np.percentile(self.TE, 75), dec),\n",
    "            round(self.TE.max(), dec)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/levi/.local/lib/python3.10/site-packages/statsmodels/miscmodels/ordinal_model.py:419: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  xb = xb[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Treatment distribution over high and low groups\n",
      "High: mean=0.1226, std=0.1881, min=0.0002, max=1.0\n",
      "Low: mean=0.0, std=0.0, min=0.0, max=0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3879.808952525429"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the process for greenspace\n",
    "green = PropensityMatching(\n",
    "    \"Green\",\n",
    "    gdf[\"DEPRESSION_RISK\"], \n",
    "    gdf['percent_green'],\n",
    "    gdf[confounders+[\"percent_blue\"]]\n",
    ")\n",
    "green.CalculatePropensityScore(10, False)\n",
    "green.DistanceMatrix()\n",
    "green.MinWeightMaximalMatch()\n",
    "green.TreatmentEffect()\n",
    "green.HighAndLowGroups()\n",
    "green.ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/levi/.local/lib/python3.10/site-packages/statsmodels/miscmodels/ordinal_model.py:419: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  xb = xb[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Treatment distribution over high and low groups\n",
      "High: mean=0.2158, std=0.2076, min=0.0281, max=1.0\n",
      "Low: mean=0.0524, std=0.0409, min=0.0, max=0.2044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-12.220740930671901"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the process for bluespace\n",
    "blue = PropensityMatching(\n",
    "    \"Blue\",\n",
    "    gdf[\"DEPRESSION_RISK\"], \n",
    "    gdf['percent_blue'],\n",
    "    gdf[confounders+[\"percent_green\"]]\n",
    ")\n",
    "blue.CalculatePropensityScore(10, False)\n",
    "blue.DistanceMatrix()\n",
    "blue.MinWeightMaximalMatch()\n",
    "blue.TreatmentEffect()\n",
    "blue.HighAndLowGroups()\n",
    "blue.ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/levi/.local/lib/python3.10/site-packages/statsmodels/miscmodels/ordinal_model.py:419: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  xb = xb[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Treatment distribution over high and low groups\n",
      "High: mean=0.3132, std=0.2629, min=0.0266, max=1.1779\n",
      "Low: mean=0.0777, std=0.0739, min=0.0, max=0.6278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "578.9067703347102"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the process for green- and bluespace\n",
    "greenblue = PropensityMatching(\n",
    "    \"Green and Blue\",\n",
    "    gdf[\"DEPRESSION_RISK\"], \n",
    "    gdf['percent_blue']+gdf[\"percent_green\"],\n",
    "    gdf[confounders]\n",
    ")\n",
    "greenblue.CalculatePropensityScore(10, False)\n",
    "greenblue.DistanceMatrix()\n",
    "greenblue.MinWeightMaximalMatch()\n",
    "greenblue.TreatmentEffect()\n",
    "greenblue.HighAndLowGroups()\n",
    "greenblue.ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/levi/.local/lib/python3.10/site-packages/statsmodels/miscmodels/ordinal_model.py:419: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  xb = xb[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Treatment distribution over high and low groups\n",
      "High: mean=0.1226, std=0.1881, min=0.0, max=1.0\n",
      "Low: mean=0.0, std=0.0, min=0.0, max=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6877/1534793314.py:72: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  te = (self.y[i] - self.y[j])/(self.z[i] - self.z[j])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the null model for greenspace\n",
    "greennull = PropensityMatching(\n",
    "    \"Green, null\",\n",
    "    gdf[\"DEPRESSION_RISK\"], \n",
    "    gdf['percent_green'],\n",
    "    gdf[confounders+[\"percent_blue\"]],\n",
    "    null = True\n",
    ")\n",
    "greennull.CalculatePropensityScore(10, False)\n",
    "greennull.DistanceMatrix()\n",
    "greennull.MinWeightMaximalMatch()\n",
    "greennull.TreatmentEffect()\n",
    "greennull.HighAndLowGroups()\n",
    "greennull.ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/levi/.local/lib/python3.10/site-packages/statsmodels/miscmodels/ordinal_model.py:419: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  xb = xb[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Treatment distribution over high and low groups\n",
      "High: mean=0.2197, std=0.2056, min=0.0303, max=1.0\n",
      "Low: mean=0.0485, std=0.034, min=0.0, max=0.1612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102.79324463728683"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the null model for bluespace\n",
    "bluenull = PropensityMatching(\n",
    "    \"Blue, null\",\n",
    "    gdf[\"DEPRESSION_RISK\"], \n",
    "    gdf['percent_blue'],\n",
    "    gdf[confounders+[\"percent_green\"]],\n",
    "    null = True\n",
    ")\n",
    "bluenull.CalculatePropensityScore(10, False)\n",
    "bluenull.DistanceMatrix()\n",
    "bluenull.MinWeightMaximalMatch()\n",
    "bluenull.TreatmentEffect()\n",
    "bluenull.HighAndLowGroups()\n",
    "bluenull.ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/levi/.local/lib/python3.10/site-packages/statsmodels/miscmodels/ordinal_model.py:419: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  xb = xb[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Treatment distribution over high and low groups\n",
      "High: mean=0.3185, std=0.2586, min=0.0436, max=1.225\n",
      "Low: mean=0.0723, std=0.0528, min=0.0, max=0.2316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-26.84802568638616"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the null model for green- and bluespace\n",
    "greenbluenull = PropensityMatching(\n",
    "    \"Green and Blue, null\",\n",
    "    gdf[\"DEPRESSION_RISK\"], \n",
    "    gdf['percent_blue']+gdf[\"percent_green\"],\n",
    "    gdf[confounders],\n",
    "    null = True\n",
    ")\n",
    "greenbluenull.CalculatePropensityScore(10, False)\n",
    "greenbluenull.DistanceMatrix()\n",
    "greenbluenull.MinWeightMaximalMatch()\n",
    "greenbluenull.TreatmentEffect()\n",
    "greenbluenull.HighAndLowGroups()\n",
    "greenbluenull.ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ATE Min 25th% 75th% Max\n",
      "Green 3879.808952525429 -350.35318542605995 -4.214504769401132 1.8040713203319458 2103.3031587583177\n",
      "Blue -12.220740930671901 -38.42281862122904 -1.4723924723269775 1.5469496506319957 41.9552685342247\n",
      "Green and Blue 578.9067703347102 -14.8050384376871 -0.5124055585884314 0.8897614885526016 292.3420235288157\n",
      "Green, null -inf -inf -3.8888831315919012 2.204309161917607 669.3278039391315\n",
      "Blue, null 102.79324463728683 -29.498088715363313 -1.0006310927059616 1.511597276480157 56.0541130041001\n",
      "Green and Blue, null -26.84802568638616 -46.31798758569894 -0.9651424334048957 1.0861855100337166 28.43657577293679\n"
     ]
    }
   ],
   "source": [
    "print(\"Name\", \"ATE\", \"Min\", \"25th%\", \"75th%\", \"Max\")\n",
    "green.DescribeTreatmentEffect()\n",
    "blue.DescribeTreatmentEffect()\n",
    "greenblue.DescribeTreatmentEffect()\n",
    "greennull.DescribeTreatmentEffect()\n",
    "bluenull.DescribeTreatmentEffect()\n",
    "greenbluenull.DescribeTreatmentEffect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
